{"cells":[{"metadata":{"_uuid":"d65e584d-489b-4c2e-9f09-fc8911e1dfce","_cell_guid":"58adfbe9-fb7a-47db-9719-5fdfe39aeec0","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"980f36b5-fb60-471d-b60b-49ba6d6754e6","_cell_guid":"d912573f-4b29-433b-9525-136370ca8e07","trusted":true},"cell_type":"code","source":"# import essentials to build cov net \n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.models import model_from_json\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ecdc1172-fbc9-45a7-86fe-19ca2ef38c71","_cell_guid":"a55bc3a3-3359-4ce8-9102-f5f797bc4c37","trusted":true},"cell_type":"code","source":"\n# ResNet-50 model\n# this is the json file that i saved in training phase\njson_file = open('/kaggle/input/transfer-learning/resnet_50_model.json', 'r')\n\n#reading model \nloaded_model_json = json_file.read()\njson_file.close()\n\n#loading model\nloaded_model = model_from_json(loaded_model_json)\n\n# loading weights into new model \nloaded_model.load_weights(\"../input/indian-currency-note-resnet-weights/currency_detector_2.4GB_earlyStopping_model.h5\")\nprint(\"Loaded model from disk\")\n \n# evaluate loaded model on test data\nloaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2b03709-1751-4e64-ba21-2809c8239089","_cell_guid":"19e3bdfa-d6cb-4b96-bca4-5bdd97d6c942","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e14228a9-9057-4e26-b291-e93e2936f02f","_cell_guid":"52e254b5-9b6f-479d-86d3-274eed30b99c","trusted":true},"cell_type":"code","source":"# These are the  class labels from the training data (Each number stands for the currency denomination)\nclass_labels = [\n    '10','100','20','200','2000','50','500','Background'\n]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cdbe1b18-ade0-451b-add1-8e1437b5d3af","_cell_guid":"c085c6df-caef-4fce-a2a0-586482a0f7df","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fd170633-0457-49e5-bbe5-780960d2fd11","_cell_guid":"4f53e28d-af29-44e4-b05c-c4fc59fc5052","trusted":true},"cell_type":"code","source":"#Dependecies \n#install ggts and pyttsx3 before execution\n\n#gTTS (Google Text-to-Speech), a Python library and CLI tool to interface with Google Translate's text-to-speech API.\n#Write spoken mp3 data to a file, a file-like object (bytestring) for further audio manipulation, or stdout. \n\n!pip install gTTS\n\n#pyttsx3 is a text-to-speech conversion library in Python.\n#Unlike alternative libraries, it works offline, and is compatible with both Python 2 and 3.\n\n!pip install pyttsx3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"6315311d-7fdc-458c-9081-3e3577ac2245","_cell_guid":"e116e5c8-409f-45bf-aa21-3a5f3b5cf89e","trusted":true},"cell_type":"code","source":"# Convert the image to a numpy array\nfrom gtts import gTTS \nfrom tensorflow.python.keras.preprocessing import image\nimport os \nimport pyttsx3\n    \n    \ndef prediction(file_name):\n    img = image.load_img(file_name, target_size=(256,256))\n\n    image_to_test = image.img_to_array(img)\n\n    #since Keras expects a list of images, not a single image,\n    # Add a fourth dimension to the image \n    \n    list_of_images = np.expand_dims(image_to_test, axis=0)\n\n    # Make a prediction using the model\n    results = loaded_model.predict(list_of_images)\n\n    # Since we are only testing one image, we only need to check the first result\n    single_result = results[0]\n\n    # We will get a likelihood score for all  possible classes.\n    # Find out which class had the highest score.\n    # the class with highest likelihood is predicted as the result.\n    \n    most_likely_class_index = int(np.argmax(single_result))\n    class_likelihood = single_result[most_likely_class_index]\n\n    # Get the name of the most likely class\n    class_label = class_labels[most_likely_class_index]\n\n    # Print the result\n    print(file_name)\n    print(\"This is image is a {} - Likelihood: {: .2f}\".format(class_label, class_likelihood))\n    \n    # convert the actual prediction result text into audio file.\n    tts(class_label,class_likelihood)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load an image file to test, resizing it to 256x256 pixels (as required by this model)\n# to save time in training I resize images to 256x256 \n\nimport matplotlib.pyplot as plt\nfrom tensorflow.python.keras.preprocessing import image\n\n# example of test image \nimg = image.load_img(\"../input/test-dataset/test/2000__359.jpg\", target_size=(256,256))\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pydub (Manipulate audio with an simple and easy high level interface)\nfrom pydub import AudioSegment\nimport IPython\n\ndef tts(class_label,class_likelihood):\n    language='en'\n    \n    # if no currency detected or uploaded image is  bagkground\n    if(class_label==\"Background\"):\n        \n        mytext=' sorry but i am detecting only  the'+class_label+', please hold the note under the camera.'\n    else:\n        mytext=\"This is  {} Rs note, and I am  {: .2f} % sure of it\".format(class_label, class_likelihood*100)\n        \n    # gTTS() converts text into the audio supports multiple languages.    \n    myobj = gTTS(text=mytext, lang=language, slow=False)\n    \n    #store audio result \n    file='result.mp3'\n    myobj.save(file) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cbdd484a-2487-498b-a5a2-1d256bb92362","_cell_guid":"400362d7-9045-4bd5-90ea-798f08185d3e","trusted":true},"cell_type":"code","source":"# predict the entire test currency images \n\nimport glob\n# Find all *.jpg files in the directory\nfile_name_list = glob.glob('../input/test-dataset/test/*.jpg')\nprint(len(file_name_list))\nfor file_name in file_name_list:\n    # print the file name \n    print(file_name)\n    \n    #predict the currency \n    prediction(file_name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. This will predict the all test images ..\nit will take time so i will cancel this.. and go for single images prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict the single image file\nfile_to_predict=\"../input/test-dataset/test/20__65.jpg\"\n\n# display currency image \nimg = image.load_img(file_to_predict, target_size=(256,256))\nplt.imshow(img)\n\n#predict the currecy \n\nprediction(file_to_predict)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9932f95e-e98f-407c-a2c7-9f9986839e00","_cell_guid":"aa5ff851-004e-4cd3-9a5d-9448ffc986d7","trusted":true},"cell_type":"code","source":"# save audio result into .mp3 file \n\npath='./result.mp3' \n    \nIPython.display.Audio(path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"180dc835-57c1-4d59-854b-f6bdea58c3d8","_cell_guid":"7ce17479-2731-4ea1-91bb-67e0c6aea256","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Thanks for watching"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}