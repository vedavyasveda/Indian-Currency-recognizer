{"cells":[{"metadata":{"_uuid":"635d526b-1e53-4ac4-ba35-c7a8358c1aca","_cell_guid":"ab7f0820-5e21-4478-b50d-8b76cb32baac","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"827b29ee-bd69-4a1e-b4db-5d84a7c5996a","_cell_guid":"60b85296-2608-499c-be55-c2df8ecf500b","trusted":true},"cell_type":"code","source":"#import basic essential libraries \nimport matplotlib.pyplot as plt\nimport path\nimport os\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"63845526-94fe-4cbb-bae5-e3b14c6ac88e","_cell_guid":"b3d7f07f-26d8-4ed6-a68b-3910693e73ed","trusted":true},"cell_type":"code","source":"# import  keras libraries to build model and conv net\nimport tensorflow as tf\nfrom tensorflow.python import keras\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense,Conv2D,MaxPooling2D,Dropout,Flatten\nfrom pathlib import Path","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df45876f-e4dc-42e2-a8c8-268fd233729e","_cell_guid":"c0b61fba-6294-46a3-aebc-f16d50af673d","trusted":true},"cell_type":"markdown","source":"# load dataset and image agumentaion "},{"metadata":{"_uuid":"17bf66db-9b60-4049-bfd8-1d0f8e63b44d","_cell_guid":"67ffdc54-e599-4aa2-8c0a-05ece5f74a62","trusted":true},"cell_type":"code","source":"# current dataset only has 4k images\n# so image agumentation to virtually increase size of dataset \n# help (ImageDataGenerator?)\n\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n\ndata_agumentation=ImageDataGenerator(rescale=0./255,\n                             shear_range=0.2,\n                             zoom_range=0.2,\n                             horizontal_flip=True,\n                             vertical_flip=True\n\n)\n\n# load training data\ntrain_data=data_agumentation.flow_from_directory(directory='../input/indian-currency-note-images-dataset-2020/Indian currency dataset v1/training',\n                                                 target_size=(256,256),\n                                                 class_mode='categorical',\n                                                batch_size=32 \n                                               )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17880d11-9d89-48c5-ae0e-52d2ddbc016b","_cell_guid":"dc96774e-677f-4749-b9d3-79ef8063d064","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c59a7903-829d-45b6-b8fa-c72aaa948c91","_cell_guid":"2433789e-7383-4df7-9ed2-e831fb60ebd8","trusted":true},"cell_type":"code","source":"#load validation data\nval_data=ImageDataGenerator().flow_from_directory(directory='../input/indian-currency-note-images-dataset-2020/Indian currency dataset v1/validation',\n                                                      target_size=(256,256),\n                                                       class_mode='categorical'\n                                                      )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model "},{"metadata":{},"cell_type":"markdown","source":"### Early stopping and callback"},{"metadata":{"_uuid":"2e663aaa-55e4-4e4e-bf01-4d274453e9d6","_cell_guid":"d99d7195-8a7b-40a4-b807-61fa2e765e0b","trusted":true},"cell_type":"code","source":"# import modelcheckpoint and earlystopping  \n\nfrom tensorflow.python.keras.callbacks import ModelCheckpoint,EarlyStopping\n\n# checkpoint monitors  the given parameter and save the model automatically\n# here given parameter to monitor is val_loss\n# it moniters the  val loss of each epoch and val_loss is lower than previous one it save the current model ad wieght\n\ncheckpoint=ModelCheckpoint(\"currency_detector_smal_model.h5\", monitor='val_loss',verbose=1, save_best_only=True,save_weights_only=False,mode='auto', period=1)\n\n# early stopping .. it stops the trainng phase if there is no improvement in the model\n# patience defines how many epoch can b ignored before forcefully stoping the model\n\nearly = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d62b96b4-bd6b-49bf-8e12-ca7efa774a3a","_cell_guid":"0cfaed08-d040-41ad-b7c3-07be27f3978f","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3eb7d311-352f-4c3b-821c-3980e06b5796","_cell_guid":"82718900-3747-4adf-b07e-b1d55ee842b1","trusted":true},"cell_type":"markdown","source":"### define model add layers and compile"},{"metadata":{"_uuid":"696ffef3-4344-4aa0-aed4-9e0a17be15e4","_cell_guid":"33dedc15-29b9-4a4d-86e0-7437e23033bc","trusted":true},"cell_type":"code","source":"# import ResNet50\n\nfrom tensorflow.keras.applications import ResNet50\n\n# total number of classes (7 diffferent currency and 1 background class)\nnum_classes = 8\n\n# load the weight\nresnet_weights_path = '../input/resnet-weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n#define the mdel\nmy_new_model = Sequential()\n\n# add the resnet to new defined model\nmy_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\n\n#last fully connected layer with softmax as a activation function\nmy_new_model.add(Dense(num_classes, activation='softmax'))\n\nmy_new_model.layers[0].trainable = False","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c1349ac-15ef-42d5-9497-8591d0153441","_cell_guid":"13031521-3c23-4812-b8a2-64f0e0544d2f","trusted":true},"cell_type":"code","source":"# compile the model with adam optimizer, categorical_croosentropy loss function\nmy_new_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fit the model with train and val dataset"},{"metadata":{"_uuid":"4d448561-38a9-4285-8e57-7c2e5d40a9b7","_cell_guid":"ca22ccda-6364-4a36-947c-3a5369667434","trusted":true},"cell_type":"code","source":"# fit the model with train data and validation data \n# epoch 50\nmy_new_model.fit_generator(\n        train_data,\n        epochs = 50,\n        validation_data=val_data,\n        callbacks=[checkpoint,early])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It almost takes 4 - 4.5 minutes for each epoch.....\n\ni already trained the model ... \n\nit stops after 40 epochs due to early stopping ...\n\nit will takes almost 2. 5 hrs to train so i will cancel this training phase...\n\nNo file is in output dorectory... after one epoch the weight file will generate and save in output directory..\nfor each imporvement the same weight file will get updated with the new weights...\nwait for the first epoch to finish.\n..\n the wights file after  1st epoch  is saved...\n \n i will cancel this training now \n \n\n\n"},{"metadata":{},"cell_type":"markdown","source":"### save model into JSON"},{"metadata":{"trusted":true},"cell_type":"code","source":"# save the json model  \n\nmodel_json = my_new_model.to_json()\nwith open(\"resnet_50_model.json\", \"w\") as json_file:\n    json_file.write(model_json)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# predication"},{"metadata":{},"cell_type":"markdown","source":"### class labels "},{"metadata":{"_uuid":"aa606e68-3e0b-4f54-a5c3-d3888cb676f2","_cell_guid":"cb57f1f9-171d-4ba7-b4f2-596d65b61673","trusted":true},"cell_type":"code","source":"# These are the  class labels from the training data (Each number stands for the currency denomination)\nclass_labels = [\n    '10','100','20','200','2000','50','500','Background'\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Show images "},{"metadata":{"_uuid":"2ca2bdfd-fd47-4903-b6e2-9149afdceae9","_cell_guid":"37454f18-9860-41a0-b01f-3750a53fe35d","trusted":true},"cell_type":"code","source":"# Load an image file to test, resizing it to 256x256 pixels\n# to save time in training I resize images to 256x256 \n\nfrom tensorflow.python.keras.preprocessing import image\n\nimg = image.load_img(\"../input/indian-currency-notes/indian_currency_new/validation/100/38.jpg\", target_size=(256,256))\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ### code for prediction"},{"metadata":{"_uuid":"a9544cff-6e65-42f9-b6c2-cf72a2c8bb6c","_cell_guid":"8f9b5aac-ef96-4eae-b73d-878625dee8e9","trusted":true},"cell_type":"code","source":"# Convert the image to a numpy array\nfrom tensorflow.python.keras.preprocessing import image\n\ndef prediction(file_name):\n    img = image.load_img(file_name, target_size=(256,256))\n\n    image_to_test = image.img_to_array(img)\n\n    # Add a fourth dimension to the image (since Keras expects a list of images, not a single image)\n    list_of_images = np.expand_dims(image_to_test, axis=0)\n\n    # Make a prediction using the model\n    results = my_new_model.predict(list_of_images)\n\n    # Since we are only testing one image, we only need to check the first result\n    single_result = results[0]\n\n    # We will get a likelihood score for all 10 possible classes. Find out which class had the highest score.\n    most_likely_class_index = int(np.argmax(single_result))\n    class_likelihood = single_result[most_likely_class_index]\n\n    # Get the name of the most likely class\n    class_label = class_labels[most_likely_class_index]\n\n    # Print the result\n    print(file_name)\n    print(\"This is image is a {} - Likelihood: {:2f}\".format(class_label, class_likelihood))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### predicting the test images "},{"metadata":{"_uuid":"280c170b-4a19-4f71-bc06-d9f365aee5fd","_cell_guid":"6d8980b3-d674-4a0d-8492-4c39870d2b27","trusted":true},"cell_type":"code","source":"\n\nfrom tensorflow.python.keras.preprocessing import image\nimg = image.load_img(\"../input/indian-currency-notes/indian_currency_new/validation/100/38.jpg\", target_size=(256,256))\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7567e87e-cd9d-4b37-8ad8-0f6e74d57f81","_cell_guid":"2274acf0-d8fd-4035-b747-ad8dd936c3be","trusted":true},"cell_type":"code","source":"import glob\n# Find all *.jpg files in the directory\nfile_name_list = glob.glob('../input/indian-currency-notes/indian_currency_new/validation/100/38.jpg')\nprint(len(file_name_list))\nfor file_name in file_name_list:\n    prediction(file_name)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cca33609-9e8a-4c9a-b1e5-80fd1a486b51","_cell_guid":"dc0e59bc-c301-4417-b4de-383648d795aa","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a96a190-07d8-4558-ac9f-ec779d660a00","_cell_guid":"949b21cf-455f-4bcd-9c09-aca9a1224df7","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}